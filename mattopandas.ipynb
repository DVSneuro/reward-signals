{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['Npoints', \n",
    "            'lapse1',\n",
    "            'lapse2', \n",
    "            'deckchoice', \n",
    "            'RT1', \n",
    "            'RT2', \n",
    "            'choice_onset', \n",
    "            'press1_onset', \n",
    "            'info_onset', \n",
    "            'partner_onset', \n",
    "            'press2_onset', \n",
    "            'aff_onset', \n",
    "            'fix1_list', \n",
    "            'fix2_list', \n",
    "            'fix3_list', \n",
    "            'fix4_list', \n",
    "            'soc_win', \n",
    "            'block', \n",
    "            'duration', \n",
    "            'frequency', \n",
    "            'stimaff', \n",
    "            'stiminf', \n",
    "            'point_total', \n",
    "            'word', \n",
    "            'rating', \n",
    "            'is_catch', \n",
    "            'partner', \n",
    "            'highval_count']\n",
    "file_list = glob.glob('data/10*/*[0-4].mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46153846153846156, 0.25, 0.35714285714285715, 0.4444444444444444, 0.4444444444444444, 0.5555555555555556, 0.5, 0.4666666666666667, 0.4444444444444444, 0.75, 0.75, 0.631578947368421, 0.5294117647058824, 0.5789473684210527, 0.5882352941176471, 0.65, 0.625, 0.9411764705882353, 0.8125, 0.8125, 0.7894736842105263, 0.7692307692307693, 0.7777777777777778, 0.8947368421052632, 1.0, 0.8823529411764706, 0.8823529411764706, 0.7647058823529411, 0.9473684210526315, 0.7777777777777778, 0.75, 0.7058823529411765, 0.6842105263157895, 0.6111111111111112, 0.5, 0.35294117647058826, 0.14285714285714285, 0.3888888888888889, 0.2, 0.5555555555555556, 0.2777777777777778, 0.29411764705882354, 0.4375, 0.21428571428571427, 0.3888888888888889, 0.5789473684210527, 0.35294117647058826, 0.16666666666666666, 0.5625, 0.5, 0.6470588235294118, 0.47058823529411764, 0.5555555555555556, 0.6666666666666666, 0.7222222222222222, 0.631578947368421, 0.7368421052631579, 0.5333333333333333, 0.75, 0.3888888888888889, 0.5555555555555556, 0.7058823529411765, 0.75, 0.75, 0.6923076923076923, 0.7058823529411765, 0.42105263157894735, 0.625, 0.5555555555555556, 0.8947368421052632, 0.5789473684210527, 0.7058823529411765, 0.8333333333333334, 0.4375, 0.35714285714285715, 0.4666666666666667, 0.2, 0.7777777777777778, 0.5, 0.7222222222222222, 0.8333333333333334, 0.7777777777777778, 0.29411764705882354, 0.375, 0.7647058823529411, 0.6875, 0.5882352941176471, 0.625, 0.7894736842105263, 0.8947368421052632, 0.5625, 0.5555555555555556, 0.7058823529411765, 0.8888888888888888, 0.7058823529411765, 0.75, 0.6470588235294118, 0.29411764705882354, 0.45454545454545453, 0.0, 0.38461538461538464, 0.6111111111111112, 0.4666666666666667, 0.6470588235294118, 0.9444444444444444] [0.21428571428571427, 0.5789473684210527, 0.5294117647058824, 0.5882352941176471, 0.6470588235294118, 0.8823529411764706, 0.5294117647058824, 0.6875, 0.5555555555555556, 0.4, 0.42857142857142855, 0.5789473684210527, 0.5555555555555556, 0.5294117647058824, 0.6470588235294118, 0.5, 0.9444444444444444, 0.9444444444444444, 0.8888888888888888, 0.6666666666666666, 0.6666666666666666, 0.6875, 0.6111111111111112, 0.7222222222222222, 0.9473684210526315, 0.7647058823529411, 0.7777777777777778, 0.8333333333333334, 1.0, 1.0588235294117647, 0.55, 0.7777777777777778, 0.6, 0.5789473684210527, 0.8888888888888888, 0.9166666666666666, 0.7333333333333333, 0.5263157894736842, 1.0, 0.5, 0.631578947368421, 0.8125, 0.5294117647058824, 0.26666666666666666, 0.25, 0.9411764705882353, 0.6666666666666666, 0.625, 1.0625, 0.8823529411764706, 0.8235294117647058, 0.9375, 0.7058823529411765, 0.9411764705882353, 0.8333333333333334, 0.7894736842105263, 0.5, 0.35294117647058826, 0.7222222222222222, 0.5789473684210527, 0.47368421052631576, 0.7894736842105263, 0.875, 0.7647058823529411, 0.8666666666666667, 0.5625, 0.5, 0.6875, 0.4444444444444444, 0.8823529411764706, 0.5555555555555556, 0.625, 0.8888888888888888, 0.5384615384615384, 0.45454545454545453, 0.45454545454545453, 0.8333333333333334, 0.3157894736842105, 0.5882352941176471, 0.5294117647058824, 1.0, 0.5294117647058824, 0.47058823529411764, 0.75, 0.6666666666666666, 0.5, 0.7058823529411765, 0.3125, 0.4375, 0.8333333333333334, 1.0, 0.6875, 1.0, 0.8235294117647058, 0.6842105263157895, 0.5555555555555556, 0.9411764705882353, 0.29411764705882354, 0.18181818181818182, 0.2, 0.3076923076923077, 0.631578947368421, 0.5555555555555556, 0.8888888888888888, 0.7894736842105263]\n"
     ]
    }
   ],
   "source": [
    "percent_switches = []\n",
    "percent_stays = []\n",
    "\n",
    "percent_stays_social_current = []\n",
    "percent_switches_social_current = []\n",
    "\n",
    "percent_stays_nonsocial_current = []\n",
    "percent_switches_nonsocial_current = []\n",
    "\n",
    "percent_stays_social_previous = []\n",
    "percent_switches_social_previous = []\n",
    "\n",
    "percent_stays_nonsocial_previous = []\n",
    "percent_switches_nonsocial_previous = []\n",
    "\n",
    "#information lower previous feedback\n",
    "#info lower\n",
    "percent_info_lower = []\n",
    "\n",
    "#info higher \n",
    "percent_info_higher = []\n",
    "\n",
    "#info lower previous -social \n",
    "percent_info_lower_sosical = []\n",
    "#info higher previous -social\n",
    "percent_info_higher_sosical = []\n",
    "\n",
    "#info lower previous -nonsocial\n",
    "percent_info_lower_nonsosical = []\n",
    "#info higher previous -nonsocial\n",
    "percent_info_higher_nonsosical = []\n",
    "\n",
    "#--affective feedback\n",
    "#win prior \n",
    "percent_win_switches = []\n",
    "percent_win_stays = []\n",
    "#loss prior\n",
    "percent_loss_switches = []\n",
    "percent_loss_stays = []\n",
    "\n",
    "#win prior- social\n",
    "percent_win_switches_social = []\n",
    "percent_win_stays_social = []\n",
    "\n",
    "#loss prior- social\n",
    "percent_loss_switches_social = []\n",
    "percent_loss_stays_social = []\n",
    "\n",
    "#win prior- nonsocial\n",
    "percent_win_switches_nonsocial = []\n",
    "percent_win_stays_nonsocial = []\n",
    "\n",
    "#loss prior- nonsocial\n",
    "percent_loss_switches_nonsocial = []\n",
    "percent_loss_stays_nonsocial = []\n",
    "\n",
    "\n",
    "for file in file_list:\n",
    "    df = pd.DataFrame([[row.flat[0] for row in line] for line in loadmat(file)['data'][0]], columns=col_list)\n",
    "    #df.to_csv(file[10:-4] + \".csv\", index = False)\n",
    "    \n",
    "    df = pd.DataFrame([[row.flat[0] for row in line] for line in loadmat(file)['data'][0]], columns=col_list)\n",
    "    \n",
    "    li = list(df.deckchoice)\n",
    "    \n",
    "    stay_switch = []\n",
    "    for i, row in enumerate(li):\n",
    "        if i > 0:\n",
    "            if row == li[i-1]:\n",
    "                stay_switch.append('stay')\n",
    "            elif (row == 11 and li[i-1] == 1) or (row == 22 and li[i-1] == 2):\n",
    "                stay_switch.append('stay-noaff')\n",
    "            elif (row == 1 and li[i-1] == 11) or (row == 2 and li[i-1] == 22):\n",
    "                stay_switch.append('stay')    \n",
    "            elif (row == 11 and li[i-1] != 1) or (row == 22 and li[i-1] != 2):\n",
    "                stay_switch.append('switch-noaff')\n",
    "            else:\n",
    "                stay_switch.append('switch')\n",
    "        else:\n",
    "            stay_switch.append('n/a')\n",
    "                \n",
    "    df['stay_switch'] = stay_switch\n",
    "        \n",
    "    #current social partner column == 1 is social\n",
    "\n",
    "    \n",
    "    #previous social prev_partner == 1 is social\n",
    "    li = list(df.partner)\n",
    "    \n",
    "    prev_partner = []\n",
    "    for i, row in enumerate(li):\n",
    "        if i > 0:\n",
    "            if li[i-1] == 1:\n",
    "                prev_partner.append(1)\n",
    "            elif li[i-1] == 0:\n",
    "                prev_partner.append(0)\n",
    "        else:\n",
    "            prev_partner.append('n/a')\n",
    "                \n",
    "    df['prev_partner'] = prev_partner\n",
    "    \n",
    "    #info current greater or less than current == 1 is greater, 0 is less, 2 is same\n",
    "    \n",
    "    li = list(df.Npoints)\n",
    "    \n",
    "    rel_points = []\n",
    "    for i, row in enumerate(li):\n",
    "        if i > 0:\n",
    "            if li[i-1] > li[i]:\n",
    "                rel_points.append(0)\n",
    "            elif li[i-1] < li[i]:\n",
    "                rel_points.append(1)\n",
    "            elif li[i-1] == li[i]:\n",
    "                rel_points.append(2)\n",
    "                \n",
    "        else:\n",
    "            rel_points.append('n/a')\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['rel_points'] = rel_points\n",
    "    \n",
    "    #win loss prior == 1 is win\n",
    "    \n",
    "    li = list(df.soc_win)   \n",
    "    \n",
    "    prior_win_loss = []\n",
    "    \n",
    "    for i, row in enumerate(li):\n",
    "        if i > 0:\n",
    "            if li[i-1] == 1:\n",
    "                prior_win_loss.append(1)\n",
    "            elif li[i-1] == 0:\n",
    "                prior_win_loss.append(0)\n",
    "        else:\n",
    "            prior_win_loss.append('n/a')\n",
    "    \n",
    "    df['prior_win_loss'] = prior_win_loss\n",
    "    \n",
    "    #stay/switch\n",
    "    valid_stays = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='stay' else False , axis=1)\n",
    "    valid_switches = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='switch' else False , axis=1)\n",
    "    \n",
    "    count_valid_stays = len(valid_stays[valid_stays == True].index)\n",
    "    count_valid_switches = len(valid_stays[valid_switches == True].index)\n",
    "    count_valid_stay_switch = count_valid_stays + count_valid_switches\n",
    "    \n",
    "    percent_stays.append(count_valid_stays / count_valid_stay_switch)\n",
    "    percent_switches.append(count_valid_switches / count_valid_stay_switch)\n",
    "    \n",
    "    #social current\n",
    "    valid_stays_social_current = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='stay' and x['partner'] == 1 else False , axis=1)\n",
    "    valid_switches_social_current = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='switch' and x['partner'] == 1 else False , axis=1)\n",
    "    \n",
    "    count_valid_stays_social_current = len(valid_stays_social_current[valid_stays_social_current == True].index)\n",
    "    count_valid_switches_social_current = len(valid_switches_social_current[valid_switches_social_current == True].index)\n",
    "    count_valid_stay_switch_social_current = count_valid_stays_social_current + count_valid_switches_social_current\n",
    "    \n",
    "    percent_stays_social_current.append(count_valid_stays_social_current / count_valid_stay_switch_social_current)\n",
    "    percent_switches_social_current.append(count_valid_switches_social_current / count_valid_stay_switch_social_current)\n",
    "    \n",
    "    #nonsocial current\n",
    "    valid_stays_nonsocial_current = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='stay' and x['partner'] == 0 else False , axis=1)\n",
    "    valid_switches_nonsocial_current = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='switch' and x['partner'] == 0 else False , axis=1) \n",
    "    \n",
    "    count_valid_stays_nonsocial_current = len(valid_stays_nonsocial_current[valid_stays_nonsocial_current == True].index)\n",
    "    count_valid_switches_nonsocial_current = len(valid_switches_nonsocial_current[valid_switches_nonsocial_current == True].index)\n",
    "    count_valid_stay_switch_nonsocial_current = count_valid_stays_nonsocial_current + count_valid_switches_nonsocial_current\n",
    "    \n",
    "    percent_stays_nonsocial_current.append(count_valid_stays_nonsocial_current / count_valid_stay_switch_nonsocial_current)\n",
    "    percent_switches_nonsocial_current.append(count_valid_switches_nonsocial_current / count_valid_stay_switch_nonsocial_current) \n",
    "    \n",
    "    #social previous\n",
    "    valid_stays_social_previous= df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='stay' and x['prev_partner'] == 1 else False , axis=1)\n",
    "    valid_switches_social_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='switch' and x['prev_partner'] == 1 else False , axis=1)\n",
    "    \n",
    "    count_valid_stays_social_previous = len(valid_stays_social_previous[valid_stays_social_previous == True].index)\n",
    "    count_valid_switches_social_previous = len(valid_switches_social_previous[valid_switches_social_previous == True].index)\n",
    "    count_valid_stay_switch_social_previous = count_valid_stays_social_previous + count_valid_switches_social_previous\n",
    "    \n",
    "    percent_stays_social_previous.append(count_valid_stays_social_previous / count_valid_stay_switch_social_previous)\n",
    "    percent_switches_social_previous.append(count_valid_switches_social_previous / count_valid_stay_switch_social_previous)\n",
    "    \n",
    "    #nonsocial previous\n",
    "    valid_stays_nonsocial_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='stay' and x['prev_partner'] == 0 else False , axis=1)\n",
    "    valid_switches_nonsocial_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='switch' and x['prev_partner'] == 0 else False , axis=1)\n",
    "    \n",
    "    count_valid_stays_nonsocial_previous = len(valid_stays_nonsocial_previous[valid_stays_nonsocial_previous == True].index)\n",
    "    count_valid_switches_nonsocial_previous = len(valid_switches_nonsocial_previous[valid_switches_nonsocial_previous == True].index)\n",
    "    count_valid_stay_switch_nonsocial_previous = count_valid_stays_nonsocial_previous + count_valid_switches_nonsocial_previous\n",
    "    \n",
    "    percent_stays_nonsocial_previous.append(count_valid_stays_nonsocial_previous / count_valid_stay_switch_nonsocial_previous)\n",
    "    percent_switches_nonsocial_previous.append(count_valid_switches_nonsocial_previous / count_valid_stay_switch_nonsocial_previous)\n",
    "    \n",
    "    #info lower/higher\n",
    "    valid_info_lower_stays_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['rel_points'] =='stay' else False , axis=1)\n",
    "    valid_info_lower_switches_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['rel_points'] =='switch' else False , axis=1)\n",
    "    \n",
    "    count_valid_info_lower_stays_previous = len(valid_info_lower_stays_previous[valid_info_lower_stays_previous == True].index)\n",
    "    count_valid_info_lower_switches_previous = len(valid_info_lower_switches_previous[valid_info_lower_switches_previous == True].index)\n",
    "    count_valid_stay_switch_info_lower_previous = count_valid_stays_nonsocial_previous + count_valid_switches_nonsocial_previous\n",
    "    \n",
    "    percent_info_lower.append(count_valid_info_lower_stays_previous / count_valid_stay_switch_info_lower_previous)\n",
    "    percent_info_higher.append(count_valid_info_lower_switches_previous / count_valid_stay_switch_info_lower_previous)\n",
    "    \n",
    "    \n",
    "    #info lower previous -social \n",
    "    #info higher previous -social\n",
    "    \n",
    "    \n",
    "    percent_info_lower_sosical = []\n",
    "    percent_info_higher_sosical = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #info lower previous -nonsocial \n",
    "    \n",
    "    #info higher previous -nonsocial\n",
    "    ##################################################\n",
    "    \n",
    "    #win prior \n",
    "    valid_win_stays_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='stay' and x['prior_win_loss'] == 1 else False , axis=1)\n",
    "    valid_win_switches_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='switch' and x['prior_win_loss'] == 1 else False , axis=1)\n",
    "    \n",
    "    count_valid_win_stays_previous = len(valid_win_stays_previous[valid_win_stays_previous == True].index)\n",
    "    count_valid_win_switches_previous = len(valid_win_switches_previous[valid_win_switches_previous == True].index)\n",
    "    count_valid_win_stay_switches_previous = count_valid_stays_nonsocial_previous + count_valid_switches_nonsocial_previous\n",
    "    \n",
    "    percent_win_switches.append(count_valid_win_switches_previous / count_valid_win_stay_switches_previous)\n",
    "    percent_win_stays.append(count_valid_win_stays_previous  / count_valid_win_stay_switches_previous)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #loss prior\n",
    "    valid_loss_stays_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='stay' and x['prior_win_loss'] == 0 else False , axis=1)\n",
    "    valid_loss_switches_previous = df.apply(lambda x: True if x['lapse1'] == 0 and x['lapse2'] == 0 and x['stay_switch'] =='switch' and x['prior_win_loss'] == 0 else False , axis=1)\n",
    "    \n",
    "    count_valid_loss_stays_previous = len(valid_loss_stays_previous[valid_loss_stays_previous == True].index)\n",
    "    count_valid_loss_switches_previous = len(valid_loss_switches_previous[valid_loss_switches_previous == True].index)\n",
    "    count_valid_loss_stay_switches_previous = count_valid_loss_stays_previous + count_valid_loss_switches_previous\n",
    "    \n",
    "    percent_loss_switches.append(count_valid_loss_stays_previous / count_valid_loss_stay_switches_previous)\n",
    "    percent_loss_stays.append(count_valid_loss_switches_previous / count_valid_loss_stay_switches_previous)\n",
    "    \n",
    "    #print(percent_loss_switches, percent_win_stays)\n",
    "    \n",
    "    #########################################\n",
    "    #win prior- social\n",
    "    \n",
    "    #loss prior- social\n",
    "    \n",
    "    #win prior- nonsocial\n",
    "    \n",
    "    #loss prior- nonsocial\n",
    "    \n",
    "print(percent_loss_switches, percent_win_stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "#social vs non social\n",
    "#points\n",
    "\n",
    "\n",
    "#spreadsheet for stay|switch\n",
    "#per subject | social previous| non social previous | social current| non-social current | info better than previous |info worse than previous|info is same |win prior | loss prior \n",
    "\n",
    "#% over valid trials - lapses and - catch\n",
    "\n",
    "#confirm onset 0 points across \n",
    "\n",
    "#make stay_switch column\n",
    "    #df['stay_switch'] =  \n",
    "    #choice_lapse = df[df.lapse1 == 1]\n",
    "    #choice_lapse['duration'] = '3000'\n",
    "    #choice_lapse['trial_type'] = 'choice_nonsoc'\n",
    "    #choice_lapse = choice_lapse[['choice_onset', 'duration', 'trial_type']]\n",
    "    #print(choice_lapse)\n",
    "    #choice_lapse = choice_lapse.rename({'choice_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #choice_lapse1 = df[df.lapse1 == 2]\n",
    "    #choice_lapse1['duration'] = '3000'\n",
    "    #choice_lapse1['trial_type'] = 'choice_nonsoc'\n",
    "    #choice_lapse1 = choice_lapse[['choice_onset', 'duration', 'trial_type']]\n",
    "    #choice_lapse1 = choice_lapse.rename({'choice_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #outcome_aff_w_soc = df[df.partner == 1][df.soc_win == 1][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #outcome_aff_w_soc['duration'] = '1500' \n",
    "    #outcome_aff_w_soc['trial_type'] = 'outcome_aff_w_soc'\n",
    "    #outcome_aff_w_soc = outcome_aff_w_soc[['aff_onset', 'duration', 'trial_type']]\n",
    "    #outcome_aff_w_soc = outcome_aff_w_soc.rename({'aff_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #outcome_aff_w_nonsoc = df[df.partner == 0][df.soc_win == 1][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #outcome_aff_w_nonsoc['duration'] = '1500' \n",
    "    #outcome_aff_w_nonsoc['trial_type'] = 'outcome_aff_w_nonsoc'\n",
    "    #outcome_aff_w_nonsoc = outcome_aff_w_nonsoc[['aff_onset', 'duration', 'trial_type']]\n",
    "    #outcome_aff_w_nonsoc = outcome_aff_w_nonsoc.rename({'aff_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #outcome_aff_l_soc = df[df.partner == 1][df.soc_win == 0][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #outcome_aff_l_soc['duration'] = '1500' \n",
    "    #outcome_aff_l_soc['trial_type'] = 'outcome_aff_l_soc'\n",
    "    #outcome_aff_l_soc = outcome_aff_l_soc[['aff_onset', 'duration', 'trial_type']]\n",
    "    #outcome_aff_l_soc = outcome_aff_l_soc.rename({'aff_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #outcome_aff_l_nonsoc = df[df.partner == 0][df.soc_win == 0][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #outcome_aff_l_nonsoc['duration'] = '1500' \n",
    "    #outcome_aff_l_nonsoc['trial_type'] = 'outcome_aff_l_nonsoc'\n",
    "    #outcome_aff_l_nonsoc = outcome_aff_l_nonsoc[['aff_onset', 'duration', 'trial_type']]\n",
    "    #outcome_aff_l_nonsoc = outcome_aff_l_nonsoc.rename({'aff_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #outcome_info_soc = df[df.partner == 1][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #outcome_info_soc['duration'] = '1500'\n",
    "    #outcome_info_soc['trial_type'] = 'outcome_info_soc'\n",
    "    #outcome_info_soc = outcome_info_soc[['info_onset', 'duration', 'trial_type']]\n",
    "    #outcome_info_soc = outcome_info_soc.rename({'info_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #outcome_info_nonsoc = df[df.partner == 0][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #outcome_info_nonsoc['duration'] = '1500'\n",
    "    #outcome_info_nonsoc['trial_type'] = 'outcome_info_nonsoc'\n",
    "    #outcome_info_nonsoc = outcome_info_nonsoc[['info_onset', 'duration', 'trial_type']]\n",
    "    #outcome_info_nonsoc = outcome_info_nonsoc.rename({'info_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #choice_soc = df[df.partner == 1][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #choice_soc['duration'] = '1500'\n",
    "    #choice_soc['trial_type'] = 'choice_soc'\n",
    "    #choice_soc = choice_soc[['choice_onset', 'duration', 'trial_type']]\n",
    "    #choice_soc = choice_soc.rename({'choice_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #choice_nonsoc = df[df.partner == 0][df.lapse1 == 0][df.lapse2 == 0]\n",
    "    #choice_nonsoc['duration'] = '3000'\n",
    "    #choice_nonsoc['trial_type'] = 'choice_nonsoc'\n",
    "    #choice_nonsoc = choice_nonsoc[['choice_onset', 'duration', 'trial_type']]\n",
    "    #choice_nonsoc = choice_nonsoc.rename({'choice_onset': 'onset'}, axis=1)\n",
    "    \n",
    "    #merged_df = pd.concat([\n",
    "    #                       choice_lapse,\n",
    "                           #choice_lapse1\n",
    "        \n",
    "    #                       ])\n",
    "    \n",
    "    #merged_df = merged_df[merged_df.onset != 0.00]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
